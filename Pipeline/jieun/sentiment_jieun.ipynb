{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fA9jg-MJNajF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "\n",
        "from kiwipiepy import Kiwi\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "import ast\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.io as pio\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import pandas as pd\n",
        "\n",
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "from transformers import BertModel\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "#* GPU 사용 시\n",
        "device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN38-gt_TbDP",
        "outputId": "838837be-ddb0-496d-9580-f550286bcf2c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh"
      ],
      "metadata": {
        "id": "K4F-gI2CQcyY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gluonnlp pandas tqdm\n",
        "# !pip install mxnet\n",
        "# !pip install sentencepiece==0.1.91\n",
        "# !pip install transformers==4.8.2\n",
        "# !pip install torch\n",
        "# !pip install kiwipiepy\n",
        "# !pip install transformers==2.5.1\n",
        "# !pip install sentencepiece"
      ],
      "metadata": {
        "id": "b_wJmYlTNjUD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/SKTBrain/KoBERT/tree/master/kobert_hf 의 kobert_tokenizer 폴더 다운\n",
        "# !pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
      ],
      "metadata": {
        "id": "2tY02SuwOIIG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/SKTBrain/KoBERT 파일 다운\n",
        "# !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "metadata": {
        "id": "WD0fURgxOSVJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/google/sentencepiece.git\n",
        "# !cd sentencepiece\n",
        "# !mkdir build\n",
        "# !cd build\n",
        "# !cmake ..\n",
        "# !make -j $(nproc)\n",
        "# !sudo make install\n",
        "# !sudo ldconfig -v"
      ],
      "metadata": {
        "id": "sPgeM_UlO4k7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO model과 tokenizer가 서로 mapping이 되어야 함\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "pipe = pipeline(\"text-classification\", model=\"nlp04/korean_sentiment_analysis_kcelectra\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlp04/korean_sentiment_analysis_kcelectra\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"nlp04/korean_sentiment_analysis_kcelectra\")"
      ],
      "metadata": {
        "id": "4R0GnQ3IOg8I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/에어비엔비/sentimentclass_csv/review_token.csv')\n",
        "text = data['text'].tolist()"
      ],
      "metadata": {
        "id": "PsW44jrLR7x9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 본인 write token 발급\n",
        "API_TOKEN = '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'"
      ],
      "metadata": {
        "id": "Egb0AnSKWWhK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_URL = \"https://api-inference.huggingface.co/models/nlp04/korean_sentiment_analysis_kcelectra\"\n",
        "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
        "\n",
        "data = {\n",
        "    \"text\": text\n",
        "}\n",
        "\n",
        "output = pd.DataFrame(data)\n",
        "\n",
        "def query_api(row):\n",
        "    payload = {\"inputs\": row[\"text\"]}\n",
        "    response = requests.post(API_URL, headers=headers, json=payload)\n",
        "    result = response.json()\n",
        "    return result\n",
        "\n",
        "tqdm.pandas()\n",
        "output[\"sentiment_result\"] = output.progress_apply(query_api, axis=1)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy2nosgdVB0j",
        "outputId": "78ba7a05-4e2d-48e6-f072-a6dbd03bd42e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 664/518135 [02:04<25:55:40,  5.54it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MzdQHbdyW2i_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}